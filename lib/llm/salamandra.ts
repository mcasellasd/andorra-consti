/**
 * Utilitat per generar text amb Salamandra-7b-instruct
 * Model especialitzat en catal√† i altres lleng√ºes ib√®riques
 * Desenvolupat per BSC (Barcelona Supercomputing Center)
 */

/**
 * Formata missatges en format ChatML (com utilitza Salamandra)
 */
function formatChatML(
  messages: Array<{ role: string; content: string }>,
  dateString?: string
): string {
  const date = dateString || new Date().toISOString().split('T')[0];

  let formatted = '';

  // System message
  if (messages[0]?.role === 'system') {
    formatted += `<|im_start|>system\n${messages[0].content}<|im_end|>\n`;
    messages = messages.slice(1);
  } else {
    formatted += `<|im_start|>system\nEts un assistent √∫til i respectu√≥s.<|im_end|>\n`;
  }

  // User/Assistant alternats
  messages.forEach(msg => {
    if (msg.role === 'user' || msg.role === 'assistant') {
      formatted += `<|im_start|>${msg.role}\n${msg.content}<|im_end|>\n`;
    }
  });

  // Generation prompt
  formatted += `<|im_start|>assistant\n`;

  return formatted;
}

/**
 * Genera text utilitzant Salamandra via endpoint personalitzat (ex: Google Colab)
 * Utilitza SALAMANDRA_API_URL del .env.local
 */
async function generateWithSalamandraCustom(
  messages: Array<{ role: string; content: string }>,
  options: {
    maxTokens?: number;
    temperature?: number;
    dateString?: string;
  } = {}
): Promise<string> {
  const customApiUrl = process.env.SALAMANDRA_API_URL;

  if (!customApiUrl) {
    throw new Error('SALAMANDRA_API_URL no configurada. Configura-la al .env.local amb la URL del teu endpoint (ex: https://xxxx.ngrok.io/generate)');
  }

  console.log(`üåê Utilitzant endpoint personalitzat: ${customApiUrl}`);

  // Retry amb backoff exponencial per errors de connexi√≥
  const maxRetries = 3;
  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(customApiUrl, {
        headers: {
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true', // Necessari per ngrok-free.app
        },
        method: 'POST',
        body: JSON.stringify({
          messages: messages,
          maxTokens: options.maxTokens || 350,
          temperature: options.temperature || 0.7,
          dateString: options.dateString,
        }),
        // Timeout de 60 segons
        signal: AbortSignal.timeout(60000),
      });

      if (!response.ok) {
        const errorText = await response.text();
        let errorMessage = `Salamandra API error (${response.status})`;

        try {
          const errorData = JSON.parse(errorText);
          if (errorData.error) {
            errorMessage = errorData.error;
          } else if (errorData.message) {
            errorMessage = errorData.message;
          }
        } catch {
          errorMessage = errorText || errorMessage;
        }

        console.error(`‚ùå Salamandra Custom API Error (${response.status}):`, errorMessage);
        throw new Error(errorMessage);
      }

      // Si arribem aqu√≠, la resposta √©s OK
      const data = await response.json();

      // L'API personalitzada hauria de retornar { generated_text: "..." }
      if (data.generated_text) {
        return data.generated_text.trim();
      }

      // Fallback: potser retorna directament el text
      if (typeof data === 'string') {
        return data.trim();
      }

      throw new Error('Resposta de l\'API sense generated_text v√†lid.');

    } catch (error: any) {
      lastError = error;

      // Errors de connexi√≥ que poden ser temporals
      const isConnectionError =
        error.code === 'ECONNRESET' ||
        error.code === 'ETIMEDOUT' ||
        error.code === 'ENOTFOUND' ||
        error.message?.includes('fetch failed') ||
        error.message?.includes('ECONNRESET') ||
        error.name === 'AbortError' ||
        error.name === 'TimeoutError';

      if (isConnectionError && attempt < maxRetries) {
        const delay = Math.min(1000 * Math.pow(2, attempt - 1), 5000); // Backoff exponencial, m√†x 5s
        console.warn(`‚ö†Ô∏è Error de connexi√≥ (intent ${attempt}/${maxRetries}). Reintentant en ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }

      // Si no √©s un error de connexi√≥ o ja hem fet tots els intents, llan√ßar l'error
      if (!isConnectionError) {
        throw error;
      }

      // Si √©s un error de connexi√≥ despr√©s de tots els intents
      console.error(`‚ùå Error Salamandra API despr√©s de ${maxRetries} intents:`, error.message);
      throw new Error(
        `Error de connexi√≥ amb Salamandra API despr√©s de ${maxRetries} intents. ` +
        `Verifica que el servidor de Colab estigui actiu i que l'URL ngrok sigui v√†lida. ` +
        `Error: ${error.message || 'Connexi√≥ tancada o timeout'}`
      );
    }
  }

  // Aix√≤ no hauria d'arribar mai, per√≤ TypeScript ho demana
  throw lastError || new Error('Error desconegut');


}

/**
 * Genera text utilitzant Salamandra via Hugging Face Inference API
 * Si SALAMANDRA_API_URL est√† configurada, utilitza l'endpoint personalitzat (ex: Google Colab)
 */
export async function generateWithSalamandra(
  messages: Array<{ role: string; content: string }>,
  options: {
    maxTokens?: number;
    temperature?: number;
    dateString?: string;
  } = {}
): Promise<string> {
  // Si hi ha un endpoint personalitzat configurat (ex: Google Colab), usar-lo
  if (process.env.SALAMANDRA_API_URL) {
    return generateWithSalamandraCustom(messages, options);
  }

  // Si no, intentar amb Hugging Face API
  const hfApiKey = process.env.HUGGINGFACE_API_KEY;

  if (!hfApiKey) {
    throw new Error('HUGGINGFACE_API_KEY √©s necess√†ria. Obt√©n-la a https://huggingface.co/settings/tokens (gratu√Øta)');
  }

  const formattedPrompt = formatChatML(messages, options.dateString);

  // Provar amb l'endpoint original primer, despr√©s router si falla
  let response: Response;

  // Opci√≥ 1: Endpoint original
  response = await fetch(
    'https://api-inference.huggingface.co/models/BSC-LT/salamandra-7b-instruct',
    {
      headers: {
        'Authorization': `Bearer ${hfApiKey}`,
        'Content-Type': 'application/json',
      },
      method: 'POST',
      body: JSON.stringify({
        inputs: formattedPrompt,
        parameters: {
          max_new_tokens: options.maxTokens || 350,
          temperature: options.temperature || 0.7,
          return_full_text: false,
        }
      })
    }
  );

  // Si l'error diu que cal usar router, provem amb router
  if (!response.ok) {
    const errorText = await response.text();
    const needsRouter = errorText.includes('router.huggingface.co') ||
      errorText.includes('no longer supported') ||
      response.status === 404;

    if (needsRouter) {
      console.log('üîÑ Endpoint original no disponible, provant amb router.huggingface.co...');
      response = await fetch(
        'https://router.huggingface.co/models/BSC-LT/salamandra-7b-instruct',
        {
          headers: {
            'Authorization': `Bearer ${hfApiKey}`,
            'Content-Type': 'application/json',
          },
          method: 'POST',
          body: JSON.stringify({
            inputs: formattedPrompt,
            parameters: {
              max_new_tokens: options.maxTokens || 350,
              temperature: options.temperature || 0.7,
              return_full_text: false,
            }
          })
        }
      );
    }
  }

  if (!response.ok) {
    const errorText = await response.text();
    let errorMessage = `Hugging Face API error (${response.status})`;

    try {
      const errorData = JSON.parse(errorText);
      if (errorData.error) {
        errorMessage = errorData.error;
      } else if (errorData.message) {
        errorMessage = errorData.message;
      }
    } catch {
      errorMessage = errorText || errorMessage;
    }

    // Log detallat de l'error per debugging
    console.error(`‚ùå Hugging Face API Error (${response.status}):`, errorMessage);
    console.error('Response text:', errorText.substring(0, 500));

    // Si el model est√† carregant, esperar i tornar a intentar
    if (response.status === 503) {
      console.log('‚è≥ Model Salamandra carregant, esperant 30 segons...');
      await new Promise(resolve => setTimeout(resolve, 30000));
      return generateWithSalamandra(messages, options);
    }

    // Si l'error menciona router o endpoint no suportat, llan√ßar error m√©s clar
    if (errorMessage.includes('router') || errorMessage.includes('no longer supported') || response.status === 404) {
      throw new Error(`Hugging Face API endpoint no disponible. Error: ${errorMessage}. Potser cal actualitzar l'endpoint o el model no est√† disponible.`);
    }

    throw new Error(errorMessage);
  }

  const data = await response.json();

  // Salamandra retorna un array amb generated_text
  if (Array.isArray(data) && data[0]?.generated_text) {
    return data[0].generated_text.trim();
  }

  // O pot retornar directament generated_text
  if (data.generated_text) {
    return data.generated_text.trim();
  }

  // Fallback
  return data[0]?.generated_text?.trim() || '';
}

/**
 * Genera text utilitzant Salamandra localment (opcional, m√©s lent)
 * Requereix m√©s recursos per√≤ √©s completament privat
 * NOTA: Usa Salamandra 2B (menys mem√≤ria que 7B, adequat per T4/Colab)
 */
export async function generateWithSalamandraLocal(
  messages: Array<{ role: string; content: string }>,
  options: {
    maxTokens?: number;
    temperature?: number;
    dateString?: string;
  } = {}
): Promise<string> {
  // Importaci√≥ din√†mica per evitar que Next.js bundli @xenova/transformers
  const { pipeline } = await import('@xenova/transformers');

  const generator = await pipeline('text-generation', 'BSC-LT/salamandra-2b-instruct', {
    quantized: true, // Necessari per estalviar mem√≤ria
  });

  const prompt = formatChatML(messages, options.dateString);
  const output = await generator(prompt, {
    max_new_tokens: options.maxTokens || 350,
    temperature: options.temperature || 0.7,
  });

  return (output as any)[0]?.generated_text?.trim() || '';
}
